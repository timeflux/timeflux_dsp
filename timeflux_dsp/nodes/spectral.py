"""This module contains nodes for spectral analysis with Timeflux."""

import numpy as np
import pandas as pd
import xarray as xr
import math
from scipy.signal import welch
from scipy.signal.spectral import fftpack
from timeflux.core.node import Node


class FFT(Node):
    """Compute the one-dimensional discrete Fourier Transform for each column using the Fast Fourier Tranform algorithm.

    Attributes:
        i (Port): default input, expects DataFrame.
        o (Port): default output, provides DataArray.

    Example:

        In this example, we simulate a white noise and we apply FFT:

         * ``rate`` = `10.0`
         * ``nfft`` = `5`
         * ``return_onesided`` = `False`

        self.i.data::

                                              A         B         C
            2017-12-31 23:59:59.998745401  0.185133  0.541901  0.872946
            2018-01-01 00:00:00.104507143  0.732225  0.806561  0.658783
            2018-01-01 00:00:00.202319939  0.692277  0.849196  0.249668
            2018-01-01 00:00:00.300986584  0.489425  0.221209  0.987668
            2018-01-01 00:00:00.396560186  0.944059  0.039427  0.705575


        self.o.data::

            xarray.DataArray (times: 1, frequency: 5, space: 3)
            array([[[ 3.043119+0.j      ,  2.458294+0.j      ,  3.47464 +0.j      ],
                    [-0.252884+0.082233j, -0.06265 -1.098709j,  0.29353 +0.478287j],
                    [-0.805843+0.317437j,  0.188256+0.146341j,  0.151515-0.674376j],
                    [-0.805843-0.317437j,  0.188256-0.146341j,  0.151515+0.674376j],
                    [-0.252884-0.082233j, -0.06265 +1.098709j,  0.29353 -0.478287j]]])
            Coordinates:
              * times     (times) datetime64[ns] 2018-01-01T00:00:00.396560186
              * frequency (frequency) float64 0.0 2.0 4.0 -4.0 -2.0
              * space     (space) object 'A' 'B' 'C'

    Notes:
       This node should be used after a Window of the appropriate length. For best performance, the window should provide
       a fixed number of samples, and that number should be a power of 2 such as 64, 128, or 256.

       The output from this node will be a complex number; to translate this into an amplitude you take it's magnitude
       by passing it through an Expression node that uses the abs() function.

    References:
        * `scipy.fftpack <https://docs.scipy.org/doc/scipy/reference/fftpack.html>`_

    """

    def __init__(self, rate=None, nfft=None, return_onesided=True):
        """
            Args:
                rate (float): Nominal sampling rate of the input data.
                nfft (int|None): Length of the Fourier transform. Default: length of the chunk.
                return_onesided (bool): If `True`, return a one-sided spectrum for real data.
                                              If `False` return a two-sided spectrum.
        """

        self._rate = rate
        self._nfft = None if nfft is None else int(nfft)

        self._onesided = return_onesided
        if self._onesided:
            self._fft = np.fft.rfft
        else:
            self._fft = fftpack.fft

        if self._nfft is not None and self._rate is not None:
            self._set_freqs()

    def _check_nfft(self):

        # Check validity of nfft at first chunk
        if self._nfft is None:
            self.logger.debug("nfft := length of the input chunk ")
            self._nfft = self.i.data.shape[0]
        elif self._nfft != self.i.data.shape[0]:
            # np & scipy will pad/truncate the input as necessary, but this may not be desired.
            self.logger.warning("FFT input chunk has length {} but nfft is {}".format(self.i.data.shape[0], self._nfft))

    def _set_freqs(self):

        # Set freqs indexes
        if self._onesided:
            self._freqs = np.fft.rfftfreq(self._nfft, 1 / self._rate)
        else:
            self._freqs = fftpack.fftfreq(self._nfft, 1 / self._rate)

    def update(self):

        # copy the meta
        self.o = self.i

        # When we have not received data, there is nothing to do
        if not self.i.ready():
            return

        # At this point, we are sure that we have some data to process
        if self._rate is None:
            if 'rate' in self.i.meta:
                self._rate = self.i.meta['rate']
            else:
                self.logger.warning("FFT using default sampling rate of 1; you should specify the rate explicitly or by meta.")
                self._rate = 1.0
        self.o.data = self.i.data
        self._check_nfft()
        if not hasattr(self, '._freqs'):
            self._set_freqs()

        values = self._fft(self.o.data.values.T, n=self._nfft).T
        self.o.data = xr.DataArray(np.stack([values], 0),
                                   coords=[[self.o.data.index[-1]], self._freqs, self.o.data.columns],
                                   dims=['time', 'frequency', 'space'])


class Welch(Node):
    """Estimate power spectral density using Welchâ€™s method.

        Attributes:
           i (Port): default input, expects DataFrame.
           o (Port): default output, provides DataArray with dimensions (time, freq, space).

        Example:

        In this example, we simulate data with noisy sinus on three sensors (columns `a`, `b`, `c`):

            * ``fs`` = `100.0`
            * ``nfft`` = `24`

        node.i.data::
            \s                       a         b         c
            1970-01-01 00:00:00.000 -0.233920 -0.343296  0.157988
            1970-01-01 00:00:00.010  0.460353  0.777296  0.957201
            1970-01-01 00:00:00.020  0.768459  1.234923  1.942190
            1970-01-01 00:00:00.030  1.255393  1.782445  2.326175
            ...                      ...       ...       ...
            1970-01-01 00:00:01.190  1.185759  2.603828  3.315607

        node.o.data::

            <xarray.DataArray (time: 1, frequency: 13, space: 3)>
            array([[[2.823924e-02, 1.087382e-01, 1.153163e-01],
                [1.703466e-01, 6.048703e-01, 6.310628e-01],
                ...            ...           ...
                [9.989429e-04, 8.519226e-04, 7.769918e-04],
                [1.239551e-03, 7.412518e-04, 9.863335e-04],
                [5.382880e-04, 4.999334e-04, 4.702757e-04]]])
            Coordinates:
                * time      (time) datetime64[ns] 1970-01-01T00:00:01.190000
                * frequency (frequency) float64 0.0 4.167 8.333 12.5 16.67 ... 37.5 41.67 45.83 50.0
                * space     (space) object 'a' 'b' 'c'

        Notes:

            This node should be used after a Window with the appropriate length, with regard to the parameters
            `noverlap`, `nperseg` and `nfft`.
            It should be noted that a pipeline such as {LargeWindow-Welch} is in fact equivalent to a pipeline
            {SmallWindow-FFT-LargeWindow-Average} with SmallWindow 's parameters `length` and `step` respectively
            equivalent to `nperseg` and `step` and with FFT node with same kwargs.

    """

    def __init__(self, rate=None, closed='right', **kwargs):
        """
            Args:
                rate (float|None): Nominal sampling rate of the input data. If `None`, the rate will be taken from the input meta/
                closed (str): Make the index closed on the `right`, `left` or `center`.
                kwargs:  Keyword arguments to pass to scipy.signal.welch function.
                                You can specify: window, nperseg, noverlap, nfft, detrend, return_onesided and scaling.
        """

        self._rate = rate
        self._closed = closed
        self._kwargs = kwargs
        self._set_default()

    def _set_default(self):
        # We set the default params if they are not specifies in kwargs in order to check that they are valid, in respect of the length and sampling of the input data.
        if 'nperseg' not in self._kwargs.keys():
            self._kwargs['nperseg'] = 256
            self.logger.debug('nperseg := 256')
        if 'nfft' not in self._kwargs.keys():
            self._kwargs['nfft'] = self._kwargs['nperseg']
            self.logger.debug('nfft := nperseg := {nperseg}'.format(nperseg=self._kwargs['nperseg']))
        if 'noverlap' not in self._kwargs.keys():
            self._kwargs['noverlap'] = self._kwargs['nperseg'] // 2
            self.logger.debug('noverlap := nperseg/2 := {noverlap}'.format(noverlap=self._kwargs['noverlap']))

    def _check_nfft(self):
        # Check validity of nfft at first chunk
        if not all(i <= len(self.i.data) for i in [self._kwargs[k] for k in ['nfft', 'nperseg', 'noverlap']]):
            raise ValueError('nfft, noverlap and nperseg must be less than or equal to length of chunk.')
        else:
            self._kwargs.update({keyword: int(self._kwargs[keyword]) for keyword in ['nfft', 'nperseg', 'noverlap']})

    def update(self):
        # copy the meta
        self.o = self.i

        # When we have not received data, there is nothing to do
        if not self.i.ready():
            return

        # Check rate
        if self._rate:
            rate = self._rate
        elif 'rate' in self.i.meta:
            rate = self.i.meta['rate']
        else:
            raise ValueError('The rate was neither explicitely defined nor found in the stream meta.')

        # At this point, we are sure that we have some data to process
        # apply welch on the data:
        self._check_nfft()
        f, Pxx = welch(x=self.i.data, fs=rate, **self._kwargs, axis=0)

        if self._closed == 'left':
            time = self.i.data.index[-1]
        elif self._closed == 'center':
            def middle(a):
                return int(np.ceil(len(a) / 2)) - 1
            time = self.i.data.index[middle(self.i.data)]
        else: # right
            time = self.i.data.index[-1]
        # f is the frequency axis and Pxx the average power of shape (Nfreqs x Nchanels)
        # we reshape Pxx to fit the ('time' x 'freq' x 'space') dimensions
        self.o.data = xr.DataArray(np.stack([Pxx], 0),
                                   coords=[[time], f, self.i.data.columns],
                                   dims=['time', 'frequency', 'space'])


class Bands(Node):
    """Averages the XArray values over freq dimension according to the frequencies bands given in arguments.

    This node selects a subset of values over the chosen dimensions, averages them along this axis and convert the result into a flat dataframe.
    This node will output as many ports bands as given bands, with their respective name as suffix.

        Attributes:
            i (Port): default output, provides DataArray with 3 dimensions (time, freq, space).
            o (Port): Default output, provides DataFrame.
            o_* (Port): Dynamic outputs, provide DataFrame.

    Notes:
        The output from this node may be a complex number; to translate this into an amplitude you can take it's magnitude
        by passing it through an Expression node that uses the abs() function.

    """

    def __init__(self, bands=None, relative=False):

        """
        Args:
           bands (dict): Define the band to extract given its name and its range.
                         An output port will be created with the given names as suffix.
            relative (bool): Whether the bands values should be expressed as absolute values, or as a proportion of the sum of the whole spectrum. Default: False.
        """
        bands = bands or {'delta': [1, 4], 'theta': [4, 8], 'alpha': [8, 12], 'beta': [12, 30]}
        self._relative = relative
        self._bands = []
        for band_name, band_range in bands.items():
            self._bands.append(dict(port=getattr(self, 'o_' + band_name),
                                    slice=slice(band_range[0], band_range[1]),
                                    meta={'bands': {'range': band_range,
                                                    'relative': relative}}))

    def update(self):

        # When we have not received data, there is nothing to do
        if not self.i.ready():
            return

        # At this point, we are sure that we have some data to process
        for band in self._bands:
            # 1. select the Xarray on freq axis in the range, 2. average along freq axis
            band_power = self.i.data.loc[{'frequency': band['slice']}].sum('frequency').values  # todo: sum
            if self._relative:
                tot_power = self.i.data.sum('frequency').values
                tot_power[tot_power == 0.0] = 1
                band_power /= tot_power
            band['port'].data = pd.DataFrame(columns=self.i.data.space.values, index=self.i.data.time.values,
                                             data=band_power)
            band['port'].meta = {**(self.i.meta or {}), **band['meta']}
